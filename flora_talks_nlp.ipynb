{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMs5ka2MqRXzj7n/K2U53N0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zhu-Pengming/Flora-Talks/blob/main/flora_talks_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "u8m9OKKARDSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 安装 tflite-model-maker 之前的其它依赖\n",
        "!pip install scann==1.3.1\n",
        "\n",
        "# 安装 tflite-model-maker\n",
        "!pip install tflite-model-maker==0.4.3\n",
        "\n",
        "# 卸载 tflite-support-nightly\n",
        "!pip uninstall -y tflite-support-nightly\n",
        "\n",
        "# 重新安装 tflite-support-nightly\n",
        "!pip install tflite-support-nightly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s-snqbN5RE4Q",
        "outputId": "656e3557-d9de-4f8e-ccec-a193bab1af9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scann==1.3.1\n",
            "  Downloading scann-1.3.1-cp310-cp310-manylinux_2_27_x86_64.whl (10.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow~=2.16.0 (from scann==1.3.1)\n",
            "  Using cached tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from scann==1.3.1) (1.25.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.0->scann==1.3.1) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.0->scann==1.3.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.0->scann==1.3.1) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.0->scann==1.3.1) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.0->scann==1.3.1) (0.2.0)\n",
            "Collecting h5py>=3.10.0 (from tensorflow~=2.16.0->scann==1.3.1)\n",
            "  Downloading h5py-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.0->scann==1.3.1) (16.0.6)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow~=2.16.0->scann==1.3.1)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.0->scann==1.3.1) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.0->scann==1.3.1) (23.2)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow~=2.16.0->scann==1.3.1)\n",
            "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.0->scann==1.3.1) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.0->scann==1.3.1) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.0->scann==1.3.1) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.0->scann==1.3.1) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.0->scann==1.3.1) (4.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.0->scann==1.3.1) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.0->scann==1.3.1) (1.62.0)\n",
            "Collecting tensorboard<2.17,>=2.16 (from tensorflow~=2.16.0->scann==1.3.1)\n",
            "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras>=3.0.0 (from tensorflow~=2.16.0->scann==1.3.1)\n",
            "  Downloading keras-3.1.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.0->scann==1.3.1) (0.36.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.16.0->scann==1.3.1) (0.42.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow~=2.16.0->scann==1.3.1) (13.7.1)\n",
            "Collecting namex (from keras>=3.0.0->tensorflow~=2.16.0->scann==1.3.1)\n",
            "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
            "Collecting optree (from keras>=3.0.0->tensorflow~=2.16.0->scann==1.3.1)\n",
            "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow~=2.16.0->scann==1.3.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow~=2.16.0->scann==1.3.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow~=2.16.0->scann==1.3.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow~=2.16.0->scann==1.3.1) (2024.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow~=2.16.0->scann==1.3.1) (3.5.2)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow~=2.16.0->scann==1.3.1)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow~=2.16.0->scann==1.3.1) (3.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow~=2.16.0->scann==1.3.1) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow~=2.16.0->scann==1.3.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow~=2.16.0->scann==1.3.1) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow~=2.16.0->scann==1.3.1) (0.1.2)\n",
            "Installing collected packages: namex, tensorboard-data-server, protobuf, optree, ml-dtypes, h5py, tensorboard, keras, tensorflow, scann\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.6.1\n",
            "    Uninstalling tensorboard-data-server-0.6.1:\n",
            "      Successfully uninstalled tensorboard-data-server-0.6.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.9.0\n",
            "    Uninstalling h5py-3.9.0:\n",
            "      Successfully uninstalled h5py-3.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.3\n",
            "    Uninstalling tensorflow-2.9.3:\n",
            "      Successfully uninstalled tensorflow-2.9.3\n",
            "  Attempting uninstall: scann\n",
            "    Found existing installation: scann 1.2.7\n",
            "    Uninstalling scann-1.2.7:\n",
            "      Successfully uninstalled scann-1.2.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.19.2 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.25.3 which is incompatible.\n",
            "tflite-support-nightly 0.4.4.dev20230716 requires protobuf<4,>=3.18.0, but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h5py-3.10.0 keras-3.1.1 ml-dtypes-0.3.2 namex-0.0.7 optree-0.11.0 protobuf-4.25.3 scann-1.3.1 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1\n",
            "Collecting tflite-model-maker==0.4.3\n",
            "  Using cached tflite_model_maker-0.4.3-py3-none-any.whl (580 kB)\n",
            "Collecting tf-models-official==2.3.0 (from tflite-model-maker==0.4.3)\n",
            "  Using cached tf_models_official-2.3.0-py2.py3-none-any.whl (840 kB)\n",
            "Collecting numpy<1.23.4,>=1.17.3 (from tflite-model-maker==0.4.3)\n",
            "  Using cached numpy-1.23.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "Requirement already satisfied: pillow>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from tflite-model-maker==0.4.3) (9.4.0)\n",
            "Requirement already satisfied: sentencepiece>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from tflite-model-maker==0.4.3) (0.1.99)\n",
            "Requirement already satisfied: tensorflow-datasets>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from tflite-model-maker==0.4.3) (4.9.4)\n",
            "Collecting fire>=0.3.1 (from tflite-model-maker==0.4.3)\n",
            "  Using cached fire-0.6.0.tar.gz (88 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tflite-model-maker==0.4.3) (24.3.25)\n",
            "Requirement already satisfied: absl-py>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from tflite-model-maker==0.4.3) (1.4.0)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from tflite-model-maker==0.4.3)\n",
            "  Using cached urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "Collecting tflite-support>=0.4.2 (from tflite-model-maker==0.4.3)\n",
            "  Using cached tflite_support-0.4.4-cp310-cp310-manylinux2014_x86_64.whl (60.8 MB)\n",
            "Collecting tensorflowjs<3.19.0,>=2.4.0 (from tflite-model-maker==0.4.3)\n",
            "  Using cached tensorflowjs-3.18.0-py3-none-any.whl (77 kB)\n",
            "Requirement already satisfied: tensorflow>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from tflite-model-maker==0.4.3) (2.16.1)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.10/dist-packages (from tflite-model-maker==0.4.3) (0.58.1)\n",
            "Collecting librosa==0.8.1 (from tflite-model-maker==0.4.3)\n",
            "  Using cached librosa-0.8.1-py3-none-any.whl (203 kB)\n",
            "Requirement already satisfied: lxml>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from tflite-model-maker==0.4.3) (4.9.4)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from tflite-model-maker==0.4.3) (6.0.1)\n",
            "Collecting matplotlib<3.5.0,>=3.0.3 (from tflite-model-maker==0.4.3)\n",
            "  Using cached matplotlib-3.4.3.tar.gz (37.9 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tflite-model-maker==0.4.3) (1.16.0)\n",
            "Collecting tensorflow-addons>=0.11.2 (from tflite-model-maker==0.4.3)\n",
            "  Using cached tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "Collecting neural-structured-learning>=1.3.1 (from tflite-model-maker==0.4.3)\n",
            "  Using cached neural_structured_learning-1.4.0-py2.py3-none-any.whl (128 kB)\n",
            "Collecting tensorflow-model-optimization>=0.5 (from tflite-model-maker==0.4.3)\n",
            "  Using cached tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "Requirement already satisfied: Cython>=0.29.13 in /usr/local/lib/python3.10/dist-packages (from tflite-model-maker==0.4.3) (3.0.9)\n",
            "INFO: pip is looking at multiple versions of tflite-model-maker to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement scann==1.2.6 (from tflite-model-maker) (from versions: 1.2.7, 1.2.8, 1.2.9, 1.2.10, 1.3.0, 1.3.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for scann==1.2.6\u001b[0m\u001b[31m\n",
            "\u001b[0mFound existing installation: tflite-support-nightly 0.4.4.dev20230716\n",
            "Uninstalling tflite-support-nightly-0.4.4.dev20230716:\n",
            "  Successfully uninstalled tflite-support-nightly-0.4.4.dev20230716\n",
            "Collecting tflite-support-nightly\n",
            "  Using cached tflite_support_nightly-0.4.4.dev20230716-cp310-cp310-manylinux2014_x86_64.whl (60.8 MB)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tflite-support-nightly) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from tflite-support-nightly) (1.25.2)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tflite-support-nightly) (24.3.25)\n",
            "Collecting protobuf<4,>=3.18.0 (from tflite-support-nightly)\n",
            "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from tflite-support-nightly) (0.4.6)\n",
            "Requirement already satisfied: pybind11>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from tflite-support-nightly) (2.12.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->tflite-support-nightly) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->tflite-support-nightly) (2.21)\n",
            "Installing collected packages: protobuf, tflite-support-nightly\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.3\n",
            "    Uninstalling protobuf-4.25.3:\n",
            "      Successfully uninstalled protobuf-4.25.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.19.2 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.3 tflite-support-nightly-0.4.4.dev20230716\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "7602c97cd5d14506b54ec7c94e0850de"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "U5KwzYmyRM3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y libportaudio2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbKHs6-326zg",
        "outputId": "275ea014-4c10-4ffb-abc1-3a8cd4b6edd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libportaudio2 is already the newest version (19.6.0-1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import text_classifier\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker.text_classifier import AverageWordVecSpec\n",
        "from tflite_model_maker.text_classifier import DataLoader\n",
        "\n",
        "from tflite_support.task import core\n",
        "from tflite_support.task import processor\n",
        "from tflite_support.task import text\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "7E9kbCWwRNQY",
        "outputId": "ac73b636-0ff1-4901-ad74-d250d81cd031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tflite_model_maker'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-c3fab2ffefef>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtflite_model_maker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtflite_model_maker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext_classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtflite_model_maker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExportFormat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tflite_model_maker'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wkX3TLeJRrjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import os\n",
        "from tflite_model_maker import text_classifier, DataLoader\n",
        "\n",
        "# 挂载 Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 文件路径\n",
        "data_dir = '/content/drive/My Drive/Flora'\n",
        "\n",
        "def replace_label(original_file, new_file):\n",
        "    # Load the original file to pandas. Since the dataset is in Excel format,\n",
        "    # we use pd.read_excel instead of pd.read_csv\n",
        "    df = pd.read_excel(original_file)\n",
        "    # Define how we want to change the label name\n",
        "    label_map = {0: 'rust', 1: 'powder'}\n",
        "\n",
        "    # Execute the label change\n",
        "    df.replace({'label': label_map}, inplace=True)\n",
        "\n",
        "    # Write the updated dataset to a new file\n",
        "    df.to_csv(new_file, index=False)\n",
        "\n",
        "# Replace the label name for both the powder and rust dataset. Then write the\n",
        "# updated CSV dataset to the current folder.\n",
        "replace_label(os.path.join(data_dir, 'cleaned_powder.xlsx'), os.path.join(data_dir, 'cleaned_powder.csv'))\n",
        "replace_label(os.path.join(data_dir, 'cleaned_rust.xlsx'), os.path.join(data_dir, 'cleaned_rust.csv'))"
      ],
      "metadata": {
        "id": "ZlNC4xcWRr1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "noIqsjhGR40w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model specification\n",
        "spec = text_classifier.AverageWordVecModelSpec()"
      ],
      "metadata": {
        "id": "xf6xeTG-R5DA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1CJqZe3VSA9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "train_data = DataLoader.from_csv(\n",
        "filename=os.path.join(data_dir, 'cleaned_powder.csv'),\n",
        "text_column='text',\n",
        "label_column='label',\n",
        "model_spec=spec,\n",
        "is_training=True)\n",
        "test_data = DataLoader.from_csv(\n",
        "filename=os.path.join(data_dir, 'cleaned_rust.csv'),\n",
        "text_column='text',\n",
        "label_column='label',\n",
        "model_spec=spec,\n",
        "is_training=False)"
      ],
      "metadata": {
        "id": "INzrI5rYSBKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Jqy-hcoZSIxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = text_classifier.create(train_data, model_spec=spec, epochs=10)"
      ],
      "metadata": {
        "id": "0BfAYm3_SI7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0BBDD25eSMRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.export(export_dir='average_word_vec')"
      ],
      "metadata": {
        "id": "2dJdKofWSMbA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}